{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a7e460e-cc07-4cb0-a40d-2a310fb28512",
      "metadata": {
        "id": "3a7e460e-cc07-4cb0-a40d-2a310fb28512"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.45.2 setfit accelerate datasets sentence-transformers protobuf wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a2b21dc-aed8-4f53-9748-75c3fef4f58a",
      "metadata": {
        "id": "4a2b21dc-aed8-4f53-9748-75c3fef4f58a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "from datasets import Dataset, load_dataset, DatasetDict\n",
        "from setfit import SetFitModel, Trainer, TrainingArguments, sample_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keys\n",
        "\n",
        "We need HuggingFace access tokens to upload the fine-tuned models to the HuggingFace repository and Weights & Biases (WandB) API keys to record the training metrics in WandB."
      ],
      "metadata": {
        "id": "PSS8zCy_27At"
      },
      "id": "PSS8zCy_27At"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbda5472-b5ea-44fb-9abb-3dc96bc2fbe1",
      "metadata": {
        "id": "dbda5472-b5ea-44fb-9abb-3dc96bc2fbe1"
      },
      "outputs": [],
      "source": [
        "os.environ[\"HF_TOKEN\"]=\"\"\n",
        "os.environ[\"WANDB_API_KEY\"]=\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to calculate F1 score"
      ],
      "metadata": {
        "id": "WQl53Yr23SB8"
      },
      "id": "WQl53Yr23SB8"
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_f1_score(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates micro and macro F1-scores given the predicted and actual labels\n",
        "\n",
        "    Parameters\n",
        "    ==========\n",
        "    y_true (numpy array): Actual labels\n",
        "    y_pred (numpy array): Predicted labels\n",
        "\n",
        "    Returns\n",
        "    =======\n",
        "    dict: A dictionary containing micro f1 and macro f1 scores.\n",
        "    \"\"\"\n",
        "    # Generate a classification report to compute detailed metrics\n",
        "    clf_dict = classification_report(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        zero_division=0,\n",
        "        output_dict=True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"micro f1\": clf_dict[\"micro avg\"][\"f1-score\"],\n",
        "        \"macro f1\": clf_dict[\"macro avg\"][\"f1-score\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "kk_39sto3RLW"
      },
      "id": "kk_39sto3RLW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset creation\n",
        "\n",
        "SetFit employs contrastive learning to finetune embedding models. This training approach involves creating positive and negative pairs of sentences. A sentence pair will be positive if both of the sentences are of the same class, and negative otherwise. For example, in the case of binary “positive”-“negative” sentiment analysis, (\"The movie was awesome\", \"I loved it\") is a positive pair, and (\"The movie was awesome\", \"It was quite disappointing\") is a negative pair.\n",
        "\n",
        "Let's assume there are 3 sentences in the dataset each with a different label. While generating contrastive pairs, we can use (sentence A, sentence B), (sentence A, sentence C)"
      ],
      "metadata": {
        "id": "r7SAlHfr2_b-"
      },
      "id": "r7SAlHfr2_b-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3410d99-e0e2-44af-a1a2-4fbf3de60ff0",
      "metadata": {
        "id": "c3410d99-e0e2-44af-a1a2-4fbf3de60ff0"
      },
      "outputs": [],
      "source": [
        "# Load the dataset from the Hugging Face Hub\n",
        "dataset = load_dataset(\"bhujith10/multi_class_classification_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a061eca2-c987-4a5c-a01b-e22e6c9b95cd",
      "metadata": {
        "id": "a061eca2-c987-4a5c-a01b-e22e6c9b95cd"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset[\"train\"]\n",
        "eval_dataset = dataset[\"val\"]\n",
        "test_dataset = dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aceed208-01ab-467a-a469-de413bc2ad72",
      "metadata": {
        "id": "aceed208-01ab-467a-a469-de413bc2ad72"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "SetFit will generate positive and negative pairs of sentences for contrastive training. Higher the number of sentences, exponential will be the number of pairs.\n",
        "Hence, we sample few sentences and then generate pairs.\n",
        "\"\"\"\n",
        "\n",
        "tmp_train_dataset = train_dataset.select(range(150)).shuffle()\n",
        "tmp_eval_dataset = eval_dataset.select(range(50)).shuffle()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SetFit"
      ],
      "metadata": {
        "id": "fVZBQbEu3c2Q"
      },
      "id": "fVZBQbEu3c2Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1ec2106-d68f-4e1a-b470-67bb2c20d131",
      "metadata": {
        "id": "f1ec2106-d68f-4e1a-b470-67bb2c20d131"
      },
      "outputs": [],
      "source": [
        "labels=['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']\n",
        "\n",
        "checkpoint = \"google-bert/bert-large-uncased\"\n",
        "\n",
        "# Load a SetFit model from Hub\n",
        "model = SetFitModel.from_pretrained(\n",
        "    checkpoint,\n",
        "    multi_target_strategy=\"one-vs-rest\",\n",
        "    use_differentiable_head=True,\n",
        "    head_params={\"out_features\": len(labels)},\n",
        "    labels=labels\n",
        ")\n",
        "\n",
        "model.to('cuda')\n",
        "\n",
        "args = TrainingArguments(\n",
        "    batch_size=4,\n",
        "    num_epochs=2,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tmp_train_dataset,\n",
        "    eval_dataset=tmp_eval_dataset,\n",
        "    metric=\"accuracy\",\n",
        "    column_mapping={\"text\": \"text\", \"labels\": \"label\"}\n",
        ")\n",
        "\n",
        "# Finetune the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1744b45-9741-45a1-b5df-724f39ac4c34",
      "metadata": {
        "id": "c1744b45-9741-45a1-b5df-724f39ac4c34"
      },
      "outputs": [],
      "source": [
        "# Push model to HuggingFace repo\n",
        "trainer.model.push_to_hub(\"bhujith10/bert-large-uncased-setfit_finetuned\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "GNliBfmP31u8"
      },
      "id": "GNliBfmP31u8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d139d50-bb9e-4281-b7f5-51536d936efa",
      "metadata": {
        "id": "0d139d50-bb9e-4281-b7f5-51536d936efa"
      },
      "outputs": [],
      "source": [
        "model = SetFitModel.from_pretrained(\n",
        "    \"bhujith10/deberta-v3-base-setfit_finetuned\",\n",
        "    labels=['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80b8536b-dc86-4b42-ab69-335511fa25b1",
      "metadata": {
        "id": "80b8536b-dc86-4b42-ab69-335511fa25b1"
      },
      "outputs": [],
      "source": [
        "# DataLoader for batching\n",
        "batch_size = 4\n",
        "dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "predicted_labels = []\n",
        "actual_labels = [sample['labels'] for sample in test_dataset]\n",
        "\n",
        "# Generate predictions in batches\n",
        "start_time = time.time()\n",
        "for i,inputs in enumerate(dataloader):\n",
        "    predictions = model.predict(inputs['text'])\n",
        "    predicted_labels.extend(list(tmp) for tmp in predictions.detach().cpu().numpy())\n",
        "end_time = time.time()\n",
        "\n",
        "print(end_time-start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a687081-1eb0-4ccf-b7b9-67fe4b50763b",
      "metadata": {
        "id": "7a687081-1eb0-4ccf-b7b9-67fe4b50763b"
      },
      "outputs": [],
      "source": [
        "calculate_f1_score(actual_labels,predicted_labels)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}